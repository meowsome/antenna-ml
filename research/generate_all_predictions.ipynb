{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85662/1012066946.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../test_data/lw.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../test_data/new leaky wave/S11_Data_combined_w_extra.csv\")\n",
    "X = df.drop(columns=['dB(S(1,1)) []'])\n",
    "complete_df = pd.DataFrame(columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all combinations of ranges \n",
    "ranges = {}\n",
    "data_cols = list(X.columns)\n",
    "for column in data_cols:\n",
    "    ranges[column] = X[column].unique().tolist()\n",
    "\n",
    "# Custom overrides\n",
    "# ranges['inset_dist [mm]'] += [0.8, 1.2]\n",
    "# ranges['L [mm]'] += [11.75, 12.25]\n",
    "# ranges['W [mm]'] += [14.2, 14.4, 14.6, 15.0, 15.2, 15.4]\n",
    "# ranges['W0 [mm]'] += [2.75, 3.25]\n",
    "# ranges['y0 [mm]'] += [3.25, 3.75, 4.25, 4.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try cartesian product in pandas instead https://stackoverflow.com/a/13270110/3675086\n",
    "ranges_df = pd.DataFrame(ranges[X.columns[0]], columns=[X.columns[0]])\n",
    "for col in complete_df.columns[1:]:\n",
    "    temp_df = pd.DataFrame(ranges[col], columns=[col])\n",
    "    ranges_df = ranges_df.merge(temp_df, how='cross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can only take about 10 mil at a time, or else we run out of ram on 64gb\n",
    "# I iteratively did this process, appending to the sqlite db everytime \n",
    "start = 0\n",
    "step = 10000000\n",
    "# ranges_df = ranges_df[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('../antenna_model_w_extra.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "cropping between 0 and 10000000\n",
      "Appended 10000000\n",
      "1\n",
      "cropping between 10000000 and 20000000\n",
      "Appended 10000000\n",
      "2\n",
      "cropping between 20000000 and 30000000\n",
      "Appended 10000000\n",
      "3\n",
      "cropping between 30000000 and 40000000\n",
      "Appended 10000000\n",
      "4\n",
      "cropping between 40000000 and 50000000\n",
      "Appended 10000000\n",
      "5\n",
      "cropping between 50000000 and 60000000\n",
      "Appended 10000000\n",
      "6\n",
      "cropping between 60000000 and 70000000\n",
      "Appended 10000000\n",
      "7\n",
      "cropping between 70000000 and 80000000\n",
      "Appended 10000000\n",
      "8\n",
      "cropping between 80000000 and 90000000\n",
      "Appended 10000000\n",
      "9\n",
      "cropping between 90000000 and 100000000\n",
      "Appended 10000000\n",
      "10\n",
      "cropping between 100000000 and 110000000\n",
      "Appended 10000000\n",
      "11\n",
      "cropping between 110000000 and 120000000\n",
      "Appended 10000000\n",
      "12\n",
      "cropping between 120000000 and 130000000\n",
      "Appended 10000000\n",
      "13\n",
      "cropping between 130000000 and 140000000\n",
      "Appended 10000000\n",
      "14\n",
      "cropping between 140000000 and 150000000\n",
      "Appended 10000000\n",
      "15\n",
      "cropping between 150000000 and 160000000\n",
      "Appended 10000000\n",
      "16\n",
      "cropping between 160000000 and 170000000\n",
      "Appended 10000000\n",
      "17\n",
      "cropping between 170000000 and 180000000\n",
      "Appended 10000000\n",
      "18\n",
      "cropping between 180000000 and 190000000\n",
      "Appended 10000000\n",
      "19\n",
      "cropping between 190000000 and 200000000\n",
      "Appended 10000000\n",
      "20\n",
      "cropping between 200000000 and 210000000\n",
      "Appended 10000000\n",
      "21\n",
      "cropping between 210000000 and 220000000\n",
      "Appended 10000000\n",
      "22\n",
      "cropping between 220000000 and 230000000\n",
      "Appended 10000000\n",
      "23\n",
      "cropping between 230000000 and 240000000\n",
      "Appended 10000000\n",
      "24\n",
      "cropping between 240000000 and 250000000\n",
      "Appended 10000000\n",
      "25\n",
      "last)\n",
      "cropping between 250000000 and 251868750\n",
      "Appended 1868750\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "count = math.ceil(ranges_df.shape[0]/step)\n",
    "for i in range(count):\n",
    "    print(i)\n",
    "\n",
    "    start = step*i\n",
    "    end = step*(i+1)\n",
    "    if i+1 == count:\n",
    "        print(\"last)\")\n",
    "        end=ranges_df.shape[0]\n",
    "\n",
    "    print(f\"cropping between {start} and {end}\")\n",
    "    \n",
    "\n",
    "    # Remove duplicates that are already calculated https://stackoverflow.com/a/47107164\n",
    "    df_all = ranges_df[start:end].merge(X.drop_duplicates(), on=X.columns.tolist(), how='left', indicator=True)\n",
    "\n",
    "    # Assign source col to predicted or simulated based on where it came from\n",
    "    # 0 = predicted, 1 = simulated\n",
    "    df_all['source_simulated'] = df_all['_merge'].apply(lambda x: 0 if x == 'left_only' else 1)\n",
    "\n",
    "    df_all.drop(columns=['_merge'], inplace=True, axis=1)\n",
    "\n",
    "    predictions = model.predict(df_all.drop(columns='source_simulated'))\n",
    "    df_all['prediction'] = predictions\n",
    "\n",
    "    # Get simulated s11 values in same order as generated data\n",
    "    # Must drop simulated s11 col because somewhere in the dataset there are multiple s11 simulations for the same geometries\n",
    "    cols_to_compare = df.columns.values.tolist()\n",
    "    cols_to_compare.remove(\"dB(S(1,1)) []\")\n",
    "\n",
    "    simulated_s11 = df.drop_duplicates(subset=cols_to_compare).sort_values(by=list(df.columns),axis=0)['dB(S(1,1)) []']\n",
    "\n",
    "    # Replace predictions for geometries that already have simulated values \n",
    "    # Make sure to only include as many as needed for each iteration \n",
    "    simulated_count= df_all[df_all['source_simulated'] == 1].shape[0]\n",
    "    df_all.loc[df_all['source_simulated'] == 1, \"prediction\"] = simulated_s11.values.tolist()[:simulated_count]\n",
    "\n",
    "    how_many = df_all.to_sql(name='geometries', con=conn, index=False, if_exists='append')\n",
    "    print(f\"Appended {how_many}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates that are already calculated https://stackoverflow.com/a/47107164\n",
    "df_all = ranges_df[start:end].merge(X.drop_duplicates(), on=X.columns.tolist(), how='left', indicator=True)\n",
    "\n",
    "# Assign source col to predicted or simulated based on where it came from\n",
    "df_all['source_simulated'] = df_all['_merge'].apply(lambda x: 'Predicted' if x == 'left_only' else 'Simulated')\n",
    "\n",
    "df_all.drop(columns=['_merge'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cpw_in [mm]            float64\n",
       "feed_l [mm]            float64\n",
       "patch_l [mm]           float64\n",
       "cpw_g [mm]             float64\n",
       "Feed_W [mm]            float64\n",
       "ground_w [mm]          float64\n",
       "patch_ground_w [mm]    float64\n",
       "patch_w [mm]           float64\n",
       "Freq [GHz]             float64\n",
       "source_simulated        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate min max and step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../test_data/patch_antenna/Patch Antenna S11 Data.csv\")\n",
    "X = df.drop(columns=['dB(S(1,1)) []'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inset_dist [mm]: Range: 0.6 - 1.4, avg: 0.9999999999999998\n",
      "[0.6, 1.0, 1.4]\n",
      "\n",
      "L [mm]: Range: 11.5 - 12.5, avg: 12.0\n",
      "[11.5, 12.0, 12.5]\n",
      "\n",
      "sub_thick [mm]: Range: 2 - 2, avg: 2.0\n",
      "[2]\n",
      "\n",
      "W [mm]: Range: 14.0 - 15.6, avg: 14.8\n",
      "[14.0, 14.8, 15.6]\n",
      "\n",
      "W0 [mm]: Range: 2.5 - 3.5, avg: 3.0\n",
      "[2.5, 3.0, 3.5]\n",
      "\n",
      "y0 [mm]: Range: 3.0 - 5.0, avg: 4.0\n",
      "[3.0, 3.5, 4.0, 4.5, 5.0]\n",
      "\n",
      "Freq [GHz]: Range: 4.0 - 12.0, avg: 8.0\n",
      "[4.0, 4.08, 4.16, 4.24, 4.32, 4.4, 4.48, 4.56, 4.64, 4.72, 4.8, 4.88, 4.96, 5.04, 5.12, 5.2, 5.28, 5.36, 5.44, 5.52, 5.6, 5.68, 5.76, 5.84, 5.92, 6.0, 6.08, 6.16, 6.24, 6.32, 6.4, 6.48, 6.56, 6.64, 6.72, 6.8, 6.88, 6.96, 7.04, 7.12, 7.2, 7.28, 7.36, 7.44, 7.52, 7.6, 7.68, 7.76, 7.84, 7.92, 8.0, 8.08, 8.16, 8.24, 8.32, 8.4, 8.48, 8.56, 8.64, 8.72, 8.8, 8.88, 8.96, 9.04, 9.12, 9.2, 9.28, 9.36, 9.44, 9.52, 9.6, 9.68, 9.76, 9.84, 9.92, 10.0, 10.08, 10.16, 10.24, 10.32, 10.4, 10.48, 10.56, 10.64, 10.72, 10.8, 10.88, 10.96, 11.04, 11.12, 11.2, 11.28, 11.36, 11.44, 11.52, 11.6, 11.68, 11.76, 11.84, 11.92, 12.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    print(f\"{col}: Range: {X[col].min()} - {X[col].max()}, avg: {X[col].mean()}\")\n",
    "    print(X[col].unique().tolist())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tylers_env_do_not_touch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
