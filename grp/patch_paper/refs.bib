@misc{Maxworth_2022, title={Antenna Design With HFSS OER}, url={https://digitalcommons.usm.maine.edu/oer_maxworth_adwafss/}, journal={University of Southern Maine Digital Commons}, publisher={University of Southern Maine}, author={Maxworth, Ashanthi}, year={2022}, month={May} }

@misc{Bevelacqua_2015, title={S-Parameters}, url={https://www.antenna-theory.com/definitions/sparameters.php}, journal={Antenna-Theory}, author={Bevelacqua, Pete}, year={2015} }

@article{john_antenna_2009,
	title = {Antenna {Optimization} {With} a {Computationally} {Efficient} {Multiobjective} {Evolutionary} {Algorithm}},
	volume = {57},
	issn = {1558-2221},
	url = {https://ieeexplore.ieee.org/document/4797981},
	doi = {10.1109/TAP.2008.2009775},
	abstract = {An efficient multiobjective evolutionary algorithm is described for optimizing a novel spline based printed monopole antenna. The antenna geometry is based on spline outlines. Both radiating element and groundplane are simultaneously optimized by the algorithm. The resulting antenna performance is evaluated. It is shown that the evolutionary algorithm and the spline geometry can be used to efficiently generate ultrawideband antennas on limited computing resources.},
	number = {1},
	urldate = {2024-01-13},
	journal = {IEEE Transactions on Antennas and Propagation},
	author = {John, Matthias and Ammann, Max J.},
	month = jan,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Antennas and Propagation},
	pages = {260--263},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tyler\\Zotero\\storage\\USN56XGA\\4797981.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tyler\\Zotero\\storage\\FNDYRPI4\\John and Ammann - 2009 - Antenna Optimization With a Computationally Effici.pdf:application/pdf},
}


@article{wu_machine_2023,
	title = {Machine {Learning}-{Assisted} {Optimization} for {Antenna} {Geometry} {Design}},
	issn = {1558-2221},
	url = {https://ieeexplore.ieee.org/document/10379000},
	doi = {10.1109/TAP.2023.3346493},
	abstract = {A machine learning-assisted optimization (MLAO) method for antenna geometry design (MLAO-AGD) is proposed. By combining machine learning (ML) methods, including a convolutional neural network and Gaussian process regression, MLAO-AGD achieves great efficient improvement compared with conventional evolutionary algorithm-assisted antenna geometry design methods. The ML methods are introduced to build surrogate models between the antenna geometry and the antenna performance and then provide predictions of potential designs during optimization. The ML-based surrogate model is iteratively updated by verified optimization results using full-wave simulations. Three antenna design examples, including multiband and broadband antenna element design tasks and a mutual coupling reduction design task, are presented to show the advantages of the proposed MLAO-AGD, which include the convergence speed and antenna performance.},
	urldate = {2024-01-13},
	journal = {IEEE Transactions on Antennas and Propagation},
	author = {Wu, Qi and Chen, Weiqi and Yu, Chen and Wang, Haiming and Hong, Wei},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Antennas and Propagation},
	pages = {1--1},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tyler\\Zotero\\storage\\RSMIMED2\\10379000.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tyler\\Zotero\\storage\\F86UQVN3\\Wu et al. - 2023 - Machine Learning-Assisted Optimization for Antenna.pdf:application/pdf},
}



@article{haque_machine_2023,
	title = {Machine learning-based technique for gain and resonance prediction of mid band {5G} {Yagi} antenna},
	volume = {13},
	copyright = {2023 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-39730-1},
	doi = {10.1038/s41598-023-39730-1},
	abstract = {In this study, we present our findings from investigating the use of a machine learning (ML) technique to improve the performance of Quasi-Yagi–Uda antennas operating in the n78 band for 5G applications. This research study investigates several techniques, such as simulation, measurement, and an RLC equivalent circuit model, to evaluate the performance of an antenna. In this investigation, the CST modelling tools are used to develop a high-gain, low-return-loss Yagi–Uda antenna for the 5G communication system. When considering the antenna’s operating frequency, its dimensions are \$\$\{0.642\}{\textbackslash}lambda \_0{\textbackslash}times \{0.583\}{\textbackslash}lambda \_0\$\$. The antenna has an operating frequency of 3.5 GHz, a return loss of \$\$-43.45\$\$dB, a bandwidth of 520 MHz, a maximum gain of 6.57 dB, and an efficiency of almost 97\%. The impedance analysis tools in CST Studio’s simulation and circuit design tools in Agilent ADS software are used to derive the antenna’s equivalent circuit (RLC). We use supervised regression ML method to create an accurate prediction of the frequency and gain of the antenna. Machine learning models can be evaluated using a variety of measures, including variance score, R square, mean square error, mean absolute error, root mean square error, and mean squared logarithmic error. Among the nine ML models, the prediction result of Linear Regression is superior to other ML models for resonant frequency prediction, and Gaussian Process Regression shows an extraordinary performance for gain prediction. R-square and var score represents the accuracy of the prediction, which is close to 99\% for both frequency and gain prediction. Considering these factors, the antenna can be deemed an excellent choice for the n78 band of a 5G communication system.},
	language = {en},
	number = {1},
	urldate = {2024-01-22},
	journal = {Scientific Reports},
	author = {Haque, Md Ashraful and Rahman, Md Afzalur and Al-Bawri, Samir Salem and Yusoff, Zubaida and Sharker, Adiba Haque and Abdulkawi, Wazie M. and Saha, Dipon and Paul, Liton Chandra and Zakariya, M. A.},
	month = aug,
	year = {2023},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Aerospace engineering, Electrical and electronic engineering},
	pages = {12590},
	file = {Full Text PDF:C\:\\Users\\Tyler\\Zotero\\storage\\RR3RAASV\\Haque et al. - 2023 - Machine learning-based technique for gain and reso.pdf:application/pdf},
}

@article{m_el-kenawy_optimized_2022,
	title = {Optimized {Ensemble} {Algorithm} for {Predicting} {Metamaterial} {Antenna} {Parameters}},
	volume = {71},
	issn = {1546-2226},
	url = {https://www.techscience.com/cmc/v71n3/46529},
	doi = {10.32604/cmc.2022.023884},
	abstract = {Metamaterial Antenna is a subclass of antennas that makes use of metamaterial to improve performance. Metamaterial antennas can overcome the bandwidth constraint associated with tiny antennas. Machine learning is receiving a lot of interest in optimizing solutions in a variety of areas. Machine learning methods are already a significant component of ongoing research and are anticipated to play a critical role in today’s technology. The accuracy of the forecast is mostly determined by the model used. The purpose of this article is to provide an optimal ensemble model for predicting the bandwidth and gain of the Metamaterial Antenna. Support Vector Machines (SVM), Random Forest, K-Neighbors Regressor, and Decision Tree Regressor were utilized as the basic models. The Adaptive Dynamic Polar Rose Guided Whale Optimization method, named AD-PRS-Guided WOA, was used to pick the optimal features from the datasets. The suggested model is compared to models based on five variables and to the average ensemble model. The findings indicate that the presented model using Random Forest results in a Root Mean Squared Error (RMSE) of (0.0102) for bandwidth and RMSE of (0.0891) for gain. This is superior to other models and can accurately predict antenna bandwidth and gain.},
	language = {en},
	number = {3},
	urldate = {2024-01-22},
	journal = {Computers, Materials \& Continua},
	author = {M. El-kenawy, El-Sayed and Ibrahim, Abdelhameed and Mirjalili, Seyedali and Zhang, Yu-Dong and Elnazer, Shaima and M. Zaki, Rokaia},
	year = {2022},
	pages = {4989--5003},
	file = {M. El-kenawy et al. - 2022 - Optimized Ensemble Algorithm for Predicting Metama.pdf:C\:\\Users\\Tyler\\Zotero\\storage\\Q59PIQKT\\M. El-kenawy et al. - 2022 - Optimized Ensemble Algorithm for Predicting Metama.pdf:application/pdf},
}


@misc{meanti_efficient_2022,
	title = {Efficient {Hyperparameter} {Tuning} for {Large} {Scale} {Kernel} {Ridge} {Regression}},
	url = {http://arxiv.org/abs/2201.06314},
	doi = {10.48550/arXiv.2201.06314},
	abstract = {Kernel methods provide a principled approach to nonparametric learning. While their basic implementations scale poorly to large problems, recent advances showed that approximate solvers can efficiently handle massive datasets. A shortcoming of these solutions is that hyperparameter tuning is not taken care of, and left for the user to perform. Hyperparameters are crucial in practice and the lack of automated tuning greatly hinders efficiency and usability. In this paper, we work to fill in this gap focusing on kernel ridge regression based on the Nystr{\textbackslash}"om approximation. After reviewing and contrasting a number of hyperparameter tuning strategies, we propose a complexity regularization criterion based on a data dependent penalty, and discuss its efficient optimization. Then, we proceed to a careful and extensive empirical evaluation highlighting strengths and weaknesses of the different tuning strategies. Our analysis shows the benefit of the proposed approach, that we hence incorporate in a library for large scale kernel methods to derive adaptively tuned solutions.},
	urldate = {2024-02-02},
	publisher = {arXiv},
	author = {Meanti, Giacomo and Carratino, Luigi and De Vito, Ernesto and Rosasco, Lorenzo},
	month = jan,
	year = {2022},
	note = {arXiv:2201.06314 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 24 pages, 3 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tyler\\Zotero\\storage\\AGGLXRZZ\\Meanti et al. - 2022 - Efficient Hyperparameter Tuning for Large Scale Ke.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tyler\\Zotero\\storage\\3DXJ23M8\\2201.html:text/html},
}


@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@misc{omalley2019kerastuner,
    title        = {KerasTuner},
    author       = {O'Malley, Tom and Bursztein, Elie and Long, James and Chollet, Fran\c{c}ois and Jin, Haifeng and Invernizzi, Luca and others},
    year         = 2019,
    howpublished = {\url{https://github.com/keras-team/keras-tuner}}
}

@incollection{BROWN2009541,
title = {3.17 - Decision Tree Modeling in Classification},
editor = {Steven D. Brown and Romá Tauler and Beata Walczak},
booktitle = {Comprehensive Chemometrics},
publisher = {Elsevier},
address = {Oxford},
pages = {541-569},
year = {2009},
isbn = {978-0-444-52701-1},
doi = {https://doi.org/10.1016/B978-044452701-1.00025-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780444527011000259},
author = {S.D. Brown and A.J. Myles},
keywords = {classification, decision tree modeling, ensemble modeling, pattern recognition, recursive partitioning},
abstract = {In this tutorial, traditional decision tree construction is introduced and the current state of decision tree modeling is briefly examined. An emphasis is placed on techniques that make decision trees well suited to handle the complexities of chemical and biochemical applications.}
}

@article{Li_2018,
   title={Boosting in the Presence of Outliers: Adaptive Classification With Nonconvex Loss Functions},
   volume={113},
   ISSN={1537-274X},
   url={http://dx.doi.org/10.1080/01621459.2016.1273116},
   DOI={10.1080/01621459.2016.1273116},
   number={522},
   journal={Journal of the American Statistical Association},
   publisher={Informa UK Limited},
   author={Li, Alexander Hanbo and Bradic, Jelena},
   year={2018},
   month=feb, pages={660–674} }

   @unpublished{interactive_Jupyter_widgets,
author = {Jupyter widgets community},
title = {ipywidgets, a GitHub repository},
year = {2015},
note = {Retrieved from https://github.com/jupyter-widgets/ipywidgets}
}


@article{liu_efficient_2014,
	title = {An {Efficient} {Method} for {Antenna} {Design} {Optimization} {Based} on {Evolutionary} {Computation} and {Machine} {Learning} {Techniques}},
	volume = {62},
	issn = {1558-2221},
	url = {https://ieeexplore.ieee.org/document/6612668},
	doi = {10.1109/TAP.2013.2283605},
	abstract = {In recent years, various methods from the evolutionary computation (EC) field have been applied to electromagnetic (EM) design problems and have shown promising results. However, due to the high computational cost of the EM simulations, the efficiency of directly using evolutionary algorithms is often very low (e.g., several weeks' optimization time), which limits the application of these methods for many industrial applications. To address this problem, a new method, called surrogate model assisted differential evolution for antenna synthesis (SADEA), is presented in this paper. The key ideas are: (1) A Gaussian Process (GP) surrogate model is constructed on-line to predict the performances of the candidate designs, saving a lot of computationally expensive EM simulations. (2) A novel surrogate model-aware evolutionary search mechanism is proposed, directing effective global search even when a traditional high-quality surrogate model is not available. Three complex antennas and two mathematical benchmark problems are selected as examples. Compared with the widely used differential evolution and particle swarm optimization, SADEA can obtain comparable results, but achieves a 3 to 7 times speed enhancement for antenna design optimization.},
	number = {1},
	urldate = {2024-01-13},
	journal = {IEEE Transactions on Antennas and Propagation},
	author = {Liu, Bo and Aliakbarian, Hadi and Ma, Zhongkun and Vandenbosch, Guy A. E. and Gielen, Georges and Excell, Peter},
	month = jan,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Antennas and Propagation},
	pages = {7--18},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Tyler\\Zotero\\storage\\PNNH9QI9\\6612668.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Tyler\\Zotero\\storage\\QTXLI9K6\\Liu et al. - 2014 - An Efficient Method for Antenna Design Optimizatio.pdf:application/pdf},
}


@ARTICLE{9119820,
  author={Cui, Liangze and Zhang, Yao and Zhang, Runren and Liu, Qing Huo},
  journal={IEEE Transactions on Antennas and Propagation}, 
  title={A Modified Efficient KNN Method for Antenna Optimization and Design}, 
  year={2020},
  volume={68},
  number={10},
  pages={6858-6866},
  keywords={Training;Antennas;Machine learning;Data models;Measurement;Kernel;Testing;Antenna optimization;K-nearest neighbor (KNN);machine learning},
  doi={10.1109/TAP.2020.3001743}}
